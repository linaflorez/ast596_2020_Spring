{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ASTR 596: FDS Homework 7: Selection Effects as Hierarchical Models\n",
    "\n",
    "\n",
    "\n",
    "## <font color='red'> When you first look at the size of the notebook, it'll be overwhelming. There is a lot of text largely to help explain things step by step. It's just really broken up into many small steps. Answers for Q1-7 are 1--2 lines each. and Q8 is 10. The PGM will take longer if you use `daft` than anything else.\n",
    "</font>\n",
    "\n",
    "\n",
    "#### So far, we've been making inferences from sample assuming that the sample we're working with is representative of the underlying population.\n",
    "\n",
    "#### This is a fantastically bad assumption, because it's almost always wrong. \n",
    "\n",
    "#### Every astronomical dataset we've used in this class exhibits *selection effects* - you saw fewer Cepheids in more distant galaxy, you saw fewer stars in SDSS in regions with high extinction, you miss variable stars with periods around 1 day because you sample the sky with the same timescale imposed by the Earth's rotation, you don't see meteors like Chelyabinsk coming in from the direction of the Sun because the background is too high to detect such faint sources...\n",
    "\n",
    "<img src=\"selection_effect.png\">\n",
    "\n",
    "#### If you imagine a forward model for the data, then there's one extra step now that impacts what you get in your sample, and so the inverse problem - learning about the population from the sample - is potentially biased by the failure to account for selection effects.\n",
    "\n",
    "#### Since selection effects enter via detection criteria, we have to incorporate these into the model.\n",
    "\n",
    "#### You're going to build a forward model for a survey incorporating selection effects."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr>\n",
    "\n",
    "We'll simulate survey observations based on a simplified model for photon-counting aperture photometry.\n",
    "\n",
    "If our model telescope has a collecting area $A$ and integrates for a time $T$, the total exposure $\\epsilon = A\\cdot T$ toward a targeted source. \n",
    "\n",
    "The expected number of source photons detected from a source with photon number flux $F$ is thus $\\epsilon \\cdot F$.\n",
    "\n",
    "Of course backgrounds and instrumental contributions to the detected photons. Sky backgrounds and integrating instrumental backgrounds (such as dark current for a CCD) can be modeled by adding a background rate, $B$, to the flux.  We'll also consider additive contamination with a fixed expected number of counts, $C$ (such as from effects like readout or amplifier noise).  \n",
    "\n",
    "The total expected number of counts from a source is:\n",
    "\\begin{align}\n",
    "\\mu(F) & = \\epsilon F + \\epsilon B + C \\\\\n",
    " & = \\epsilon F + \\nu\n",
    "\\end{align}\n",
    "\n",
    "with $\\nu \\equiv \\epsilon B + C$ denoting the expected number of non-source photons. We'll assume that all the exposures are the same.\n",
    "\n",
    "In this setup, the data from the observation of a source comprise a single integer, the observed number of counts in aperture, $n$ (we'll use $n_i$ when we consider multiple sources, with $i$ being the source index).\n",
    "\n",
    "<hr>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color='blue'>\n",
    "\n",
    "#### Q1. To *simulate* observations, we need to specify a *sampling distribution* telling us how to generate data when the *source* properties are specified. We've encountered this distribution multiple times already (remember you don't get a non-integer number of photons). Write down an expression for the sampling distribution for the number of photons $n$ given the source flux $F$\n",
    "\n",
    "\n",
    "##### Your expression here\n",
    "\n",
    "</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# and implement the distribution in code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr>\n",
    "<font color='blue'>\n",
    "    \n",
    "#### Q2. Once we have simulated data, we need the *likelihood function* $\\ell(F)$ in order to estimate the source flux $F$ given the detected photons $n$ except now we have to take into account the noise model. Write down an expression for the likelihood function for the source Flux, given the number of photons $n$.\n",
    "\n",
    "##### Your expression here\n",
    "    \n",
    "</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# and implement the likelihood function in code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Remember that the likelihood is *not normalized over flux*  - it isn't meaningful to integrate it over $F$ without multiplication by a prior (such as a candidate population distribution for $F$).  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr> \n",
    "<font color='blue'>\n",
    "\n",
    "#### Q3. The $n$-dependent MLE estimate of the source flux, $\\hat{F}(n)$, can be found by setting $\\ell'(\\hat{F}) = 0$. Write down the maximum likelihood estimate of the flux.\n",
    "\n",
    "##### Your expression here\n",
    "    \n",
    "</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# and implement the maximum likelihood estimate here\n",
    "\n",
    "# you can sanity check your work here by interpreting this expression and seeing if it makes sense"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr>\n",
    "<font color='blue'>\n",
    "\n",
    "#### Q4. The $n$-dependent standard deviation of the Gaussian can be found by computing a second derivative of the likelihood and matching it to the second derivative of the Gaussian.\n",
    "\n",
    "##### Your expression here\n",
    "    \n",
    "</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# and implement the estimate for the uncertaintity in the source flux F here\n",
    "\n",
    "# you can sanity check your work here by looking at how this expression scales with the number of detected photons n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr>\n",
    "\n",
    "<img src=\"selection_effect_so_far.png\">\n",
    "\n",
    "OK, if we're good up to here, we've specified how to go from observables ($F$) to measurements ($n$) i.e. we know given a source with flux, $F$ we use the sampling distribution to get an estimate of the number of photons $n$ \n",
    "\n",
    "We now have to specify a **population distribution** for sources - what's the distribution of $F$ itself across sources.\n",
    "\n",
    "We'll use a version of a power-law distribution.\n",
    "\n",
    "Let $g(F; \\theta)$ denote the flux distribution probability density function $PDF$, with parameters $\\theta$ (that we will sometimes suppress for notational brevity).  \n",
    "\n",
    "\n",
    "It's annoying to have to think about behavior in terms of the actual flux in ergs/cm^2/sec so instead let us convert to a dimensionless flux. If we choose a *fiducial flux*, $F_0$ - maybe a physically interesting scale (e.g., a solar luminosity at 10 pc), or simply a convenient unit (e.g., $10^{-7}$ photons/cm$^2$/s), then we can switch to log space using:\n",
    "\n",
    "$$\n",
    "x = \\log\\left(\\frac{F}{F_0}\\right), \\qquad\\qquad\n",
    "y = \\log\\left(\\frac{g(F)}{g(F_0)}\\right).\n",
    "$$\n",
    "\n",
    "A power law is a straight line in $(x,y)$ space; its slope is the *power law index* (sometimes the negative slope is called the index).  \n",
    "\n",
    "That is, if\n",
    "\n",
    "$$\n",
    "g(F) = C\\left(\\frac{F}{F_0}\\right)^\\alpha,\n",
    "$$\n",
    "\n",
    "with $C$ a normalization constant, then \n",
    "\n",
    "$$\n",
    "\\frac{dy}{dx} = \\alpha.\n",
    "$$\n",
    "\n",
    "\n",
    "Let's generalize this a bit, seeking to make the power law index vary with flux.  Let's pick $F_0$ to be the flux at which the slope is $\\alpha$, and let the slope change linearly away from there. This leads to\n",
    "$$\n",
    "\\frac{dy}{dx} = \\alpha + \\beta x.\n",
    "$$\n",
    "\n",
    "This corresponds to power law behavior with index $\\alpha$ at $\\xi$, but with the index linearly \"rolling\" with respect to log-flux.\n",
    "\n",
    "\n",
    "What does such a choice for the transformed log flux $x$ imply for the real flux $F$ distribution? First note that although $g(F)$ is a PDF for $F$, it's not the case that $y(x)$ is a PDF for $x$.  The nonlinear change of variables from $F$ to $x$ means that the PDF for $x$, $h(x)$, must be computed using a Jacobian:\n",
    "\n",
    "\\begin{align}\n",
    "h(x) \n",
    "  &= g(F(x))\\left|\\frac{dF}{dx}\\right| \\\\\n",
    "  &= g[F_0 e^x]\\, F_0 e^x.\n",
    "\\end{align}\n",
    "\n",
    "Conversely, if we specify the PDF for the log-flux, we can compute $g(F)$ via\n",
    "\\begin{align}\n",
    "g(F) \n",
    "  &= h(x(F))\\left|\\frac{dx}{dF}\\right| \\\\\n",
    "  &= \\frac{1}{F} h[\\log(F/F_0)].\n",
    "\\end{align}\n",
    "(Check the dimensions again!)\n",
    "\n",
    "If $h(x)$ is a normal distribution (for $x$, the log-flux), with mean $\\mu$ and standard deviation $\\sigma$ (both dimensionless). We then have\n",
    "$$\n",
    "h(x) = \\frac{1}{\\sigma\\sqrt{2\\pi}} \\exp\\left[-\\frac{(x - \\mu)^2}{2\\sigma^2}\\right].\n",
    "$$\n",
    "\n",
    "\n",
    "This corresponds to a $g(F)$ given by the Jacobian rule above:\n",
    "$$\n",
    "g(F) = \\frac{1}{F}\\cdot\\frac{1}{\\sigma\\sqrt{2\\pi}} \\exp\\left[-\\frac{(\\log(F/F_0) - \\mu)^2}{2\\sigma^2}\\right].\n",
    "$$\n",
    "This is a *log-normal distribution* for the flux.\n",
    "\n",
    "\n",
    "Now compute its slope in $(x,y)$ log space.  The result is\n",
    "$$\n",
    "\\frac{dy}{dx} = \\left(\\frac{\\mu}{\\sigma^2} - 1\\right) - \\frac{x}{\\sigma^2}.\n",
    "$$\n",
    "\n",
    "Comparing with our linearly-rolling law, above, we see that a log-normal distribution corresponds to a rolling power law with index $\\alpha = \\mu/\\sigma^2 -1$ at $F=F_0$, and with rate of change of slope $\\beta = -1/\\sigma^2$.  Note that $\\beta$ must be negative.\n",
    "\n",
    "So a log-normal flux distribution will look like a power law with index $\\alpha = \\mu/\\sigma^2-1$ if $\\beta$ is small (i.e., $\\sigma$ is large). Estimating $\\beta$ measures departure from pure power law behavior.\n",
    "\n",
    "\n",
    "## Phew."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color='blue'>\n",
    "    \n",
    "#### Q5. Given alpha and beta, write code that implements a log-normal flux PDF\n",
    "\n",
    "#### Scipy of course has this, **but see the note here bout SciPy's funky scale param**:\n",
    "    \n",
    "https://docs.scipy.org/doc/scipy/reference/generated/scipy.stats.lognorm.html\n",
    "  \n",
    "##### Plot the PDF as a function of the dimensionless flux $F/F_0$ with a log-log scale\n",
    "    \n",
    "</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "alpha, beta = -1.5, -0.25  # fiducial index, roll rate\n",
    "f_vals = logspace(log10(0.03), log10(100), 250)\n",
    "\n",
    "# implement the log-normal population PDF in terms of the dimensionless flux F/F_0\n",
    "\n",
    "# plot the population PDF in log-log scales"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr> \n",
    "\n",
    "Finally, the presence of backgrounds means that photons will be counted in an aperture even in the absence of a source.  \n",
    "\n",
    "To guard against false detections, we introduce a detection threshold, $n_{\\rm threshold}$, requiring that $n > n_{\\rm th}$ for a candidate source to enter the survey catalog.  For simplicity, we'll choose $n_{\\rm threshold}$ large enough that the probability for a false detection is negligible, so the catalog is \"pure\" with high probability.\n",
    "\n",
    "The cost of purity is missing sources - we reject dim sources that happen to produce counts below threshold - our catalog is **incomplete**.\n",
    "\n",
    "To account for this, we need the *detection efficiency*, $\\eta(F)$, the probability for detecting a source of flux $F$.  This is just the probability of getting $n > n_{\\rm th}$ when $F$ is given:\n",
    "\n",
    "\\begin{align}\n",
    "\\eta(F) \n",
    "  &= p(n > n_{\\rm th}|F) \\\\\n",
    "  &= \\sum_{i=n_{\\rm th}+1}^\\infty p(n|F)\n",
    "\\end{align}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color='blue'>\n",
    "    \n",
    "#### Q6. To write this as an expression for the detection efficiency $\\eta(F)$, consider the [Incomplete gamma function - Wikipedia](https://en.wikipedia.org/wiki/Incomplete_gamma_function). \n",
    "\n",
    "#### The combination $P(s,x) \\equiv \\gamma(s,x)/\\Gamma(s)$ (with $\\Gamma(s)$ the gamma function) is called the regularized lower incomplete gamma function; SciPy provides this as `scipy.special.gammainc(s,x)`.  When $s$ is an integer, $\\Gamma(s) = (s-1)!$\n",
    "\n",
    "##### Your expression here for the detection efficiency here\n",
    "    \n",
    "</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# and implement the detection efficiency here\n",
    "\n",
    "# plot the detection efficiency as a function of the dimensionless flux in linear-linear axes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Parameter choices\n",
    "\n",
    "For our simulation we must specify the survey parameters governing measurement and detection, and a choice of parameters for the underlying \"true\" flux distribution.\n",
    "\n",
    "First let's specify the detection threshold.  \n",
    "\n",
    "A convenient and common specification is to choose $n_{\\rm th}$ so that $\\hat{F}(n_{\\rm th})$ is some fixed multiple, $k$, of the uncertainty, $\\sigma_F(n_{\\rm th})$ (i.e., we require detections to be above \"$k$ sigma\").  This corresponds to solving\n",
    "$$\n",
    "\\hat{F}(n_{\\rm th}) = k\\, \\sigma_F(n_{\\rm th})\n",
    "$$\n",
    "for $n_{\\rm th}$.  \n",
    "\n",
    "This gives an equation involving $n_{\\rm th}$ and $\\sqrt{n_{\\rm th}}$, i.e., a quadratic equation for $\\sqrt{n_{\\rm th}}$.  The solution is\n",
    "$$\n",
    "n_{\\rm th} = k^2\\, \\left(\\frac{1 + \\sqrt{1 + 4\\nu/k^2}}{2}\\right)^2.\n",
    "$$\n",
    "Note that if the expected background contribution $\\nu=0$, we have $n_{\\rm th} = k^2$, a result we would have guessed from the root-$n$ rule.\n",
    "\n",
    "#### As a starting point, let's use a 4-$\\sigma$ detection criterion, with $\\nu = 9.373$, for which\n",
    "$$\n",
    "\\large\n",
    "n_{\\rm th} = 2 k^2 = 32.\n",
    "$$\n",
    "\n",
    "Now we must specify the effective area and integration time, or equivalently, the exposure, $\\epsilon$.  Since only the product, $\\epsilon F$, enters the calculations, for any choice of flux scale, we can find an exposure that will produce any desired photon count expectation value.  \n",
    "\n",
    "#### We'll choose the exposure so that the expected counts will equal $n_{\\rm th}$ for a flux $F = 0.1 F_0$; that is, we set\n",
    "$$\n",
    "\\large \n",
    "0.1 \\epsilon F_0 + \\nu = n_{\\rm th},\n",
    "$$\n",
    "\n",
    "which gives \n",
    "\n",
    "#### $$\\epsilon = 320/F_0$$  \n",
    "\n",
    "We can set $F_0$ to a specific value; alternatively we can work in terms of a dimensionless flux, $f = F/F_0$. \n",
    "\n",
    "#### For the population model, let's set the index at $F_0$ to have rolled off of the canonical homogenous population value, $\\alpha = -5/2$, by one, i.e., $\\alpha = -1.5$.  As a starting point we'll consider $\\beta = -0.25$.  When the flux reaches $\\approx 50\\times F_0$, the log-slope reaches the $-5/2$ value.\n",
    "\n",
    "\n",
    "#### THAT'S EVERYTHING SPECIFIED IN THE FIGURE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr> \n",
    "\n",
    "<font color='blue'>\n",
    "\n",
    "#### Q7. OK, so now apply the detection efficiency to the population distribution, and show the original distribution vs the detected population that is subject to selection effects (aka \"thinned\"). As you've hopefully realized from the Q5., it'll pay to work in log-log axes. \n",
    "    \n",
    "</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot the thinned population - i.e. the population distribution subject to selection effects - log-log again"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color='blue'>\n",
    "    \n",
    "#### Q8. Monte-Carlo time! \n",
    "\n",
    "#### Simulate a catalog with 10,000 **detections**. Because of selection effects there'd better be more underlying sources than the ones you detected. \n",
    "\n",
    "* Draw the latent (true) fluxes from the **population distribution** - keep a track of these true fluxes\n",
    "* The total expected number of photons $\\mu(F) = \\epsilon F + \\nu$ again - keep a track of these true counts\n",
    "* Using your answer for Q1 i.e. the **sampling distribution** to simulate a signal\n",
    "* Using your answer for Q3 i.e. the MLE estimate of the flux (which depends on what you did in Q2), estimate the flux of your signal - keep a track of these estimated fluxes\n",
    "* Just because a process generated a signal does not mean that you detected that signal. Apply the detection threshold n_threshold to the signals you simulated\n",
    "* Keep generating until you 10,000 detections\n",
    "\n",
    "Finally, plot the true vs estimated fluxes for all signals you simulated in red, and the signals you actually detected in blue.\n",
    "\n",
    "Histogram the estimated flux for all signals and detected signals and compare to your answer for Q7. You'll need to use log-log again.\n",
    "\n",
    "</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# These will hold the data, i.e., counts.\n",
    "all_cts, detected_cts = [], []\n",
    "\n",
    "# Keep track of true fluxes.\n",
    "true_flux, detected_true_flux = [], []\n",
    "\n",
    "# These will hold dimensionless flux estimates.\n",
    "est_flux, detected_est_flux = [], []\n",
    "\n",
    "\n",
    "# YOUR MONTECARLO CODE HERE - LOOK AT HW3 IF YOU NEED A REFRESHER \n",
    "\n",
    "# PLOT true vs estimated flux for all and only detected signals here - log-log\n",
    "\n",
    "# Histogram estimated fluxes for all and detected signals and compare to Q7."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr>\n",
    "\n",
    "<font color='blue'>\n",
    "\n",
    "#### Q9. Draw the PGM for the forward model you just simulated.\n",
    "\n",
    "</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:fds] *",
   "language": "python",
   "name": "conda-env-fds-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
